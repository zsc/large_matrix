<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第14章：大规模协同过滤的矩阵技术</title>
    <link rel="stylesheet" href="./assets/style.css">
    <link rel="stylesheet" href="./assets/highlight.css">
    <script src="./assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <ul class="nav-list"><li class=""><a href="./index.html">高级大规模矩阵计算教程</a></li><li class=""><a href="./chapter1.html">第1章：二阶优化的统一框架</a></li><li class=""><a href="./chapter2.html">第2章：Hessian近似的艺术</a></li><li class=""><a href="./chapter3.html">第3章：结构化二阶方法</a></li><li class=""><a href="./chapter4.html">第4章：增量Hessian计算</a></li><li class=""><a href="./chapter5.html">第5章：Schur补的妙用</a></li><li class=""><a href="./chapter6.html">第6章：矩阵Sketching技术</a></li><li class=""><a href="./chapter7.html">第7章：随机化数值线性代数</a></li><li class=""><a href="./chapter8.html">第8章：分布式矩阵运算</a></li><li class=""><a href="./chapter9.html">第9章：异步优化的数学基础</a></li><li class=""><a href="./chapter10.html">第10章：Riemannian优化基础</a></li><li class=""><a href="./chapter11.html">第11章：流形预条件技术</a></li><li class=""><a href="./chapter12.html">第12章：结构化矩阵的快速算法</a></li><li class=""><a href="./chapter13.html">第13章：动态低秩近似</a></li><li class="active"><a href="./chapter14.html">第14章：大规模协同过滤的矩阵技术</a></li><li class=""><a href="./chapter15.html">第15章：实时推荐的增量矩阵方法</a></li><li class=""><a href="./chapter16.html">第16章：多模态推荐的张量分解</a></li><li class=""><a href="./chapter17.html">第17章：隐式微分与双层优化</a></li><li class=""><a href="./chapter18.html">第18章：量子启发的矩阵算法</a></li><li class=""><a href="./chapter19.html">附录A：数值稳定性速查表</a></li><li class=""><a href="./chapter20.html">附录B：性能调优检查清单</a></li><li class=""><a href="./chapter21.html">附录C：常用矩阵恒等式</a></li><li class=""><a href="./CLAUDE.html">高级大规模矩阵计算教程项目说明</a></li><li class=""><a href="./README.html">高级大规模矩阵计算教程</a></li></ul>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="14">第14章：大规模协同过滤的矩阵技术</h1>
<p>推荐系统是现代互联网服务的核心组件，而矩阵分解技术则是其数学基石。本章深入探讨在处理数十亿用户和数百万物品时，如何设计和优化矩阵计算方法。我们将重点关注隐式反馈场景——这是实际系统中最常见但也最具挑战性的设置。通过学习本章，读者将掌握工业级推荐系统背后的核心矩阵技术，理解从理论到实践的关键权衡，并能够设计适合特定场景的高效算法。</p>
<h2 id="141">14.1 隐式反馈矩阵分解的加权策略</h2>
<h3 id="1411">14.1.1 隐式反馈与显式评分的本质差异</h3>
<p>在显式评分系统中，用户主动为物品打分（如1-5星），我们可以直接将评分矩阵 $\mathbf{R} \in \mathbb{R}^{m \times n}$ 分解为：
$$\mathbf{R} \approx \mathbf{P}\mathbf{Q}^T$$
其中 $\mathbf{P} \in \mathbb{R}^{m \times k}$ 是用户因子矩阵，$\mathbf{Q} \in \mathbb{R}^{n \times k}$ 是物品因子矩阵。</p>
<p>然而，隐式反馈（点击、浏览、购买等）带来了根本性的挑战：</p>
<ol>
<li>
<p><strong>正样本偏差</strong>：观察到的交互不等同于偏好强度
   - 高频点击可能源于UI位置而非真实兴趣
   - 购买行为受价格、库存等外部因素影响
   - 浏览时长受内容长度和用户空闲时间影响
   - 批量操作（如清空购物车）引入噪声
   - 季节性和促销活动造成的行为异常</p>
</li>
<li>
<p><strong>负样本缺失</strong>：未交互不等于不感兴趣
   - 用户未发现的优质内容（曝光偏差）
   - 时间限制导致的未消费（机会成本）
   - 平台推荐算法造成的过滤气泡
   - 新物品的冷启动问题
   - 地理限制或内容授权导致的不可达</p>
</li>
<li>
<p><strong>置信度差异</strong>：不同类型交互的可靠性不同
   - 购买 &gt; 收藏 &gt; 点赞 &gt; 点击 &gt; 曝光
   - 重复行为比单次行为更可靠
   - 主动搜索比被动浏览更能反映真实意图
   - 深度交互（评论、分享）比浅层交互更有价值
   - 付费行为比免费行为更能反映真实偏好</p>
</li>
</ol>
<p><strong>数学建模的范式转变</strong>：</p>
<p>从概率角度，显式评分可以建模为：
$$P(r_{ui} | \mathbf{p}_u, \mathbf{q}_i) = \mathcal{N}(r_{ui}; \mathbf{p}_u^T\mathbf{q}_i, \sigma^2)$$
而隐式反馈需要考虑两阶段过程：</p>
<ol>
<li><strong>偏好生成</strong>：$\text{preference}_{ui} \sim \text{Bernoulli}(\sigma(\mathbf{p}_u^T\mathbf{q}_i))$</li>
<li><strong>观察过程</strong>：$\text{observed}_{ui} | \text{preference}_{ui} \sim \text{Bernoulli}(p_{\text{obs}})$</li>
</ol>
<p>这导致我们需要重新设计目标函数：
$$\min_{\mathbf{P},\mathbf{Q}} \sum_{(u,i) \in \mathcal{D}} c_{ui}(p_{ui} - \mathbf{p}_u^T\mathbf{q}_i)^2 + \lambda(|\mathbf{P}|_F^2 + |\mathbf{Q}|_F^2)$$
其中 $c_{ui}$ 是置信度权重，$p_{ui}$ 是偏好指示器（通常二值化）。</p>
<p><strong>数学本质</strong>：从期望最大化(EM)角度理解</p>
<ul>
<li>E步：基于当前模型推断缺失的负反馈</li>
<li>M步：在加权的完整数据上更新参数</li>
<li>权重 $c_{ui}$ 反映了我们对观察值的信任程度</li>
</ul>
<p><strong>理论联系</strong>：隐式反馈矩阵分解与其他机器学习方法的深层联系：</p>
<ol>
<li>
<p><strong>与排序学习的关系</strong>：
   隐式反馈MF可以视为全局排序模型：
$$P(i \succ j | u) = \sigma(\mathbf{p}_u^T(\mathbf{q}_i - \mathbf{q}_j))$$</p>
</li>
<li>
<p><strong>与点过程的联系</strong>：
   用户行为序列可建模为标记时空点过程：
$$\lambda(t,i|u) = \mu_i \cdot \exp(\mathbf{p}_u^T\mathbf{q}_i) \cdot g(t-t_{\text{last}})$$</p>
</li>
<li>
<p><strong>与图神经网络的对应</strong>：
   矩阵分解等价于在二部图上的浅层图嵌入：
$$\mathbf{h}_u = \text{Aggregate}({\mathbf{q}_i : i \in \mathcal{N}(u)})$$
<strong>实践考虑</strong>：工业系统中的额外复杂性</p>
</li>
<li>
<p><strong>多设备行为聚合</strong>：
$$c_{ui} = f_{\text{device}}({c_{ui}^{(d)} : d \in \text{devices}(u)})$$
需要识别和合并跨设备的用户身份</p>
</li>
<li>
<p><strong>会话内行为建模</strong>：
   短期兴趣与长期偏好的分离：
$$\mathbf{p}_u(t) = \alpha \mathbf{p}_u^{\text{long}} + (1-\alpha) \mathbf{p}_u^{\text{session}}(t)$$</p>
</li>
<li>
<p><strong>位置偏差校正</strong>：
$$c_{ui} = c_{ui}^{\text{raw}} \cdot \frac{1}{b_{\text{position}}(k)}$$
其中 $k$ 是物品在列表中的位置</p>
</li>
</ol>
<h3 id="1412">14.1.2 置信度矩阵的构建原理</h3>
<p>置信度矩阵 $\mathbf{C}$ 的设计直接影响模型质量。经典的Hu等人提出的线性置信度函数：
$$c_{ui} = 1 + \alpha \cdot r_{ui}$$
其中 $r_{ui}$ 是原始交互强度（如播放次数）。</p>
<p><strong>理论基础</strong>：将置信度视为观测噪声的倒数
$$\text{Var}[\epsilon_{ui}] = \frac{\sigma^2}{c_{ui}}$$
这意味着交互次数越多，观测越可靠，方差越小。</p>
<p><strong>从信息论角度理解置信度</strong>：
置信度可以解释为每次观察提供的信息量：
$$I(r_{ui}; r_{ui}^*) = \frac{1}{2}\log\left(1 + \frac{c_{ui}\sigma_r^2}{\sigma_\epsilon^2}\right)$$
其中 $r_{ui}^*$ 是真实偏好，$\sigma_r^2$ 是偏好方差，$\sigma_\epsilon^2$ 是观测噪声方差。</p>
<p><strong>高级置信度设计考虑因素</strong>：</p>
<ol>
<li><strong>时间衰减</strong>：
$$c_{ui}(t) = c_{ui} \cdot \exp(-\beta(t - t_{ui}))$$</li>
</ol>
<ul>
<li>半衰期选择：$t_{1/2} = \frac{\ln 2}{\beta}$</li>
<li>典型值：新闻类 $t_{1/2} = 1\text{天}$，电影类 $t_{1/2} = 30\text{天}$</li>
<li>自适应衰减率：$\beta_i = \beta_0 \cdot (1 + \text{entropy}({t_{ui}}_{u}))$</li>
</ul>
<ol start="2">
<li><strong>用户活跃度归一化</strong>：
$$\tilde{c}_{ui} = \frac{c_{ui}}{\sqrt{\sum_j c_{uj}}}$$</li>
</ol>
<ul>
<li>防止超级活跃用户主导模型更新</li>
<li>保证梯度贡献的公平性</li>
<li>理论依据：保持用户对损失函数的贡献期望相等</li>
</ul>
<ol start="3">
<li><strong>物品流行度惩罚</strong>：
$$\hat{c}_{ui} = c_{ui} \cdot \left(\frac{N}{\text{count}(i)}\right)^\gamma$$</li>
</ol>
<ul>
<li>降低热门物品的权重，促进长尾发现</li>
<li>$\gamma \in [0, 0.5]$ 控制惩罚强度</li>
<li>动态调整：$\gamma(t) = \gamma_0 \cdot (1 - \text{coverage}(t))$</li>
</ul>
<p><strong>实用性扩展</strong>：</p>
<ol start="4">
<li><strong>上下文感知置信度</strong>：
$$c_{ui}(\mathbf{x}) = c_{ui} \cdot f_{\theta}(\mathbf{x}_{ui})$$
其中 $\mathbf{x}_{ui}$ 包含：</li>
</ol>
<ul>
<li>设备类型（移动端行为通常噪声更大）</li>
<li>时段（深夜浏览vs工作时间）</li>
<li>地理位置（本地内容vs全球内容）</li>
<li>网络状态（加载速度影响完成率）</li>
</ul>
<ol start="5">
<li><strong>多行为融合</strong>：
$$c_{ui} = \sum_{a \in \mathcal{A}} w_a \cdot c_{ui}^{(a)}$$
行为权重的学习方法：</li>
</ol>
<ul>
<li>基于AUC的权重优化：$w_a \propto \text{AUC}_a$</li>
<li>互信息最大化：$w_a \propto I(a; \text{purchase})$</li>
<li>注意力机制：$w_a = \text{softmax}(\mathbf{W}^T[\mathbf{u}_a, \mathbf{i}_a])$</li>
</ul>
<ol start="6">
<li>
<p><strong>自适应置信度学习</strong>：
   使用元学习优化置信度函数参数：
$$\alpha^* = \arg\min_\alpha \mathbb{E}_{\mathcal{T} \sim p(\mathcal{T})}[\mathcal{L}_{\text{val}}(\mathcal{T}, \alpha)]$$
<strong>MAML风格的置信度元学习</strong>：
   ```
   对于每个任务 T（如不同类目）：</p>
</li>
<li>
<p>初始化置信度参数 α</p>
</li>
<li>在T的训练集上进行k步梯度下降得到 α'_T</li>
<li>在T的验证集上评估 L(α'_T)</li>
<li>更新元参数：α ← α - η∇_α Σ_T L(α'_T)
   ```</li>
</ol>
<p><strong>高级置信度建模技术</strong>：</p>
<ol start="7">
<li>
<p><strong>概率置信度</strong>：
   使用贝塔分布建模不确定性：
$$c_{ui} \sim \text{Beta}(\alpha_{ui}, \beta_{ui})$$
其中 $\alpha_{ui} = 1 + n_{ui}^+$（正交互次数），$\beta_{ui} = 1 + n_{ui}^-$（负交互次数）</p>
</li>
<li>
<p><strong>神经置信度网络</strong>：
$$c_{ui} = \text{NN}_\phi([\mathbf{u}_{\text{feat}}, \mathbf{i}_{\text{feat}}, \mathbf{x}_{ui}])$$
端到端学习复杂的置信度模式</p>
</li>
<li>
<p><strong>因果置信度</strong>：
   考虑混淆因子的影响：
$$c_{ui} = \frac{P(r_{ui}|do(expose_i))}{P(r_{ui}|expose_i)}$$
通过因果推断估计真实的兴趣强度</p>
</li>
</ol>
<p><strong>置信度的数值稳定性考虑</strong>：</p>
<ol>
<li>
<p><strong>截断处理</strong>：
$$c_{ui} = \min(\max(c_{ui}, c_{\min}), c_{\max})$$
典型值：$c_{\min} = 1$, $c_{\max} = 1000$</p>
</li>
<li>
<p><strong>平滑处理</strong>：
$$c_{ui} = \frac{c_{ui} + \epsilon}{1 + \epsilon}$$
避免极端值导致的数值问题</p>
</li>
<li>
<p><strong>对数变换</strong>：
   对于重尾分布的交互次数：
$$c_{ui} = 1 + \alpha \log(1 + r_{ui})$$</p>
</li>
</ol>
<h3 id="1413">14.1.3 加权正则化的数学推导</h3>
<p>标准L2正则化假设所有参数同等重要，但在隐式反馈中，我们需要考虑：</p>
<ol>
<li><strong>用户侧加权正则化</strong>：
$$R_u(\mathbf{p}_u) = \lambda_u |\mathbf{p}_u|^2, \quad \lambda_u = \lambda \cdot n_u^{-\beta}$$
其中 $n_u$ 是用户交互数，$\beta \in [0,1]$ 控制正则化强度的衰减。</li>
</ol>
<p><strong>推导</strong>：从最大后验(MAP)估计出发
$$\mathbf{p}_u^* = \arg\max_{\mathbf{p}_u} p(\mathbf{p}_u|\mathcal{D}_u) = \arg\max_{\mathbf{p}_u} p(\mathcal{D}_u|\mathbf{p}_u)p(\mathbf{p}_u)$$
用户活跃度越高，先验的影响应该越小：
$$p(\mathbf{p}_u) = \mathcal{N}(0, \frac{\sigma^2}{n_u^\beta}\mathbf{I})$$
<strong>信息论解释</strong>：
   用户交互数可视为有效样本大小，根据最小描述长度(MDL)原理：
$$\text{MDL} = -\log p(\mathcal{D}_u|\mathbf{p}_u) + \frac{k}{2}\log n_u$$
第二项自然导出与 $n_u$ 相关的正则化。</p>
<ol start="2">
<li><strong>物品侧自适应正则化</strong>：
$$R_i(\mathbf{q}_i) = \lambda_i |\mathbf{q}_i - \mathbf{q}_i^{(0)}|^2$$
其中 $\mathbf{q}_i^{(0)}$ 是基于内容的先验嵌入。</li>
</ol>
<p><strong>分层贝叶斯解释</strong>：
$$\mathbf{q}_i \sim \mathcal{N}(\mathbf{q}_i^{(0)}, \sigma_i^2\mathbf{I})$$
   $$\mathbf{q}_i^{(0)} = f_{\text{content}}(\mathbf{x}_i)$$
<strong>先验学习</strong>：
   使用变分自编码器学习物品先验分布：
$$q(\mathbf{q}_i^{(0)}|\mathbf{x}_i) = \mathcal{N}(\mu_\phi(\mathbf{x}_i), \text{diag}(\sigma^2_\phi(\mathbf{x}_i)))$$
<strong>理论依据</strong>：从贝叶斯角度，这相当于对参数施加不同方差的高斯先验：
$$p(\mathbf{p}_u) \propto \exp\left(-\frac{\lambda_u}{2}|\mathbf{p}_u|^2\right)$$
<strong>高级正则化技术</strong>：</p>
<ol start="3">
<li><strong>结构化稀疏正则化</strong>：
$$R(\mathbf{p}_u) = \lambda_1 |\mathbf{p}_u|_1 + \lambda_2 |\mathbf{p}_u|_2^2 + \lambda_3 \sum_{g} |\mathbf{p}_{u,g}|_2$$</li>
</ol>
<ul>
<li>L1项：全局稀疏性</li>
<li>L2项：数值稳定性</li>
<li>群组范数：结构化稀疏（如主题相关的因子组）</li>
</ul>
<p><strong>近端梯度算法求解</strong>：
$$\mathbf{p}_u^{(t+1)} = \text{prox}_{\lambda R}(\mathbf{p}_u^{(t)} - \eta \nabla \mathcal{L})$$
其中近端算子有闭式解。</p>
<ol start="4">
<li>
<p><strong>图正则化</strong>：
   构建用户-用户相似图 $\mathcal{G}_u = (\mathcal{V}_u, \mathcal{E}_u, \mathbf{W}_u)$：
$$R_{\text{graph}}(\mathbf{P}) = \frac{\lambda_g}{2} \sum_{(u,v) \in \mathcal{E}_u} w_{uv}|\mathbf{p}_u - \mathbf{p}_v|^2$$
<strong>谱分析</strong>：
$$R_{\text{graph}}(\mathbf{P}) = \lambda_g \cdot \text{tr}(\mathbf{P}^T\mathbf{L}_u\mathbf{P})$$
其中 $\mathbf{L}_u = \mathbf{D}_u - \mathbf{W}_u$ 是图拉普拉斯矩阵。</p>
</li>
<li>
<p><strong>时变正则化</strong>：
   考虑用户兴趣漂移：
$$R_t(\mathbf{p}_u) = \lambda_t |\mathbf{p}_u^{(t)} - \mathbf{p}_u^{(t-1)}|^2$$
<strong>卡尔曼滤波视角</strong>：
   <code>状态方程：p_u(t) = p_u(t-1) + w_u(t), w_u ~ N(0, Q)
   观测方程：r_ui(t) = p_u(t)^T q_i + v_ui(t), v_ui ~ N(0, R)</code></p>
</li>
<li>
<p><strong>对抗正则化</strong>：
   提高模型鲁棒性：
$$R_{\text{adv}}(\mathbf{P}, \mathbf{Q}) = \lambda_{\text{adv}} \max_{|\delta|_2 \leq \epsilon} \mathcal{L}(\mathbf{P} + \delta_P, \mathbf{Q} + \delta_Q)$$
使用FGSM近似：
$$\delta_P = \epsilon \cdot \text{sign}(\nabla_P \mathcal{L})$$
<strong>正则化的自适应选择</strong>：</p>
</li>
<li>
<p><strong>经验贝叶斯方法</strong>：
   通过最大化边际似然自动确定正则化强度：
$$\lambda^* = \arg\max_\lambda \int p(\mathcal{D}|\mathbf{P}, \mathbf{Q}) p(\mathbf{P}, \mathbf{Q}|\lambda) d\mathbf{P}d\mathbf{Q}$$
使用拉普拉斯近似：
$$\log p(\mathcal{D}|\lambda) \approx \log p(\mathcal{D}|\hat{\mathbf{P}}, \hat{\mathbf{Q}}) - \frac{1}{2}\log\det(\mathbf{H} + \lambda\mathbf{I})$$</p>
</li>
<li>
<p><strong>多任务学习正则化</strong>：
   当有多个相关推荐任务时：
$$R_{\text{MTL}} = \sum_{t=1}^T \lambda_t |\mathbf{P}^{(t)}|_F^2 + \lambda_{\text{share}}\sum_{t \neq s}|\mathbf{P}^{(t)} - \mathbf{P}^{(s)}|_F^2$$
促进任务间的知识共享。</p>
</li>
</ol>
<p><strong>正则化与优化的交互</strong>：</p>
<ol start="9">
<li>
<p><strong>隐式正则化</strong>：
   SGD本身具有隐式正则化效果：
$$\mathbf{p}_u^{(t+1)} = \mathbf{p}_u^{(t)} - \eta \nabla_{\mathcal{B}} \mathcal{L}$$
其中批量大小 $|\mathcal{B}|$ 和学习率 $\eta$ 的比值 $\eta/|\mathcal{B}|$ 控制隐式正则化强度。</p>
</li>
<li>
<p><strong>正则化路径算法</strong>：
    高效计算不同 $\lambda$ 下的解：
$${\mathbf{P}(\lambda), \mathbf{Q}(\lambda)}_{\lambda \in [\lambda_{\min}, \lambda_{\max}]}$$
利用解的分段线性性质，通过跟踪关键点高效求解。</p>
</li>
</ol>
<h3 id="1414">14.1.4 研究前沿：因果推断视角</h3>
<p>最新研究将隐式反馈建模为带有选择偏差的因果推断问题：</p>
<ol>
<li><strong>倾向分数加权</strong>：
$$\mathcal{L} = \sum_{(u,i) \in \mathcal{D}} \frac{1}{p(o_{ui}=1|u,i)} \ell(r_{ui}, \hat{r}_{ui})$$
<strong>关键挑战</strong>：</li>
</ol>
<ul>
<li>倾向分数 $p(o_{ui}=1|u,i)$ 通常未知</li>
<li>极小的倾向分数导致方差爆炸</li>
<li>需要平衡偏差-方差权衡</li>
</ul>
<ol start="2">
<li><strong>反事实风险最小化</strong>：
$$\mathcal{L}_{IPS} = \frac{1}{|\mathcal{D}|}\sum_{(u,i) \in \mathcal{D}} \frac{\ell(r_{ui}, \hat{r}_{ui})}{p(o_{ui}=1)} + \lambda R(\theta)$$
<strong>稳定化技术</strong>：</li>
</ol>
<ul>
<li>截断倾向分数：$\tilde{p} = \max(p, \epsilon)$</li>
<li>自归一化估计器：$\hat{\mathcal{L}}_{SNIPS} = \frac{\sum_{(u,i)} w_{ui}\ell_{ui}}{\sum_{(u,i)} w_{ui}}$</li>
</ul>
<ol start="3">
<li>
<p><strong>双鲁棒估计</strong>：
   结合直接方法和倾向分数方法：
$$\hat{r}_{DR} = \hat{r}_{DM} + \frac{o_{ui}}{p(o_{ui}=1)}(r_{ui} - \hat{r}_{DM})$$
即使倾向分数或直接模型之一有误差，仍能保持一致性</p>
</li>
<li>
<p><strong>因果嵌入</strong>：
   学习满足因果约束的表示：
$$\mathbf{p}_u \perp!!!\perp \mathbf{e}_u | \mathbf{z}_u$$
其中 $\mathbf{e}_u$ 是混淆因子，$\mathbf{z}_u$ 是因果表示</p>
</li>
</ol>
<p><strong>前沿研究方向</strong>：</p>
<ul>
<li>
<p><strong>去混淆表示学习</strong>：
$$\min_{\theta} \mathcal{L}_{rec} + \alpha \cdot I(\mathbf{Z}; \mathbf{E})$$
最小化因果表示与混淆因子的互信息</p>
</li>
<li>
<p><strong>因果效应估计</strong>：
$$\text{ATE} = \mathbb{E}[Y(1) - Y(0)]$$
估计推荐某物品的平均处理效应</p>
</li>
<li>
<p><strong>敏感性分析</strong>：
  量化未观测混淆的影响：
$$\Gamma = \max_{u,i,j} \frac{p(o_{ui}=1|u,j)p(o_{uj}=1|u,i)}{p(o_{ui}=1|u,i)p(o_{uj}=1|u,j)}$$
这为处理推荐系统中的偏差问题开辟了新方向，特别是在公平性和可解释性日益重要的背景下。</p>
</li>
</ul>
<h2 id="142-als-wr">14.2 ALS-WR算法的并行化与数值优化</h2>
<h3 id="1421">14.2.1 交替最小二乘的计算复杂度分析</h3>
<p>ALS-WR (Alternating Least Squares with Weighted Regularization) 的核心是交替固定一组参数，优化另一组。对于用户 $u$，更新方程为：
$$\mathbf{p}_u = (\mathbf{Q}^T\mathbf{C}^u\mathbf{Q} + \lambda\mathbf{I})^{-1}\mathbf{Q}^T\mathbf{C}^u\mathbf{p}(u)$$
其中 $\mathbf{C}^u$ 是用户 $u$ 的对角置信度矩阵。</p>
<p><strong>计算复杂度分解</strong>：</p>
<ul>
<li>朴素实现：$O(n^2k + nk^2 + k^3)$ per user</li>
<li>利用稀疏性：$O(n_u k^2 + k^3)$，其中 $n_u \ll n$</li>
</ul>
<p><strong>关键优化</strong>：预计算 $\mathbf{Q}^T\mathbf{Q}$，复杂度降至 $O(n_u k^2)$。</p>
<p><strong>详细算法分析</strong>：</p>
<ol>
<li>
<p><strong>矩阵分解技巧</strong>：
$$\mathbf{Q}^T\mathbf{C}^u\mathbf{Q} = \mathbf{Q}^T\mathbf{Q} + \mathbf{Q}^T(\mathbf{C}^u - \mathbf{I})\mathbf{Q}$$
由于 $\mathbf{C}^u - \mathbf{I}$ 只在用户交互的物品上非零：
$$\mathbf{Q}^T(\mathbf{C}^u - \mathbf{I})\mathbf{Q} = \sum_{i \in \mathcal{I}_u} (c_{ui} - 1)\mathbf{q}_i\mathbf{q}_i^T$$</p>
</li>
<li>
<p><strong>计算步骤优化</strong>：
   ```
   预计算阶段 (一次性)：</p>
</li>
</ol>
<ul>
<li>计算 G = Q^T Q: O(nk^2)</li>
<li>存储需求: O(k^2)</li>
</ul>
<p>用户更新阶段 (每个用户)：</p>
<ul>
<li>构建 A_u = G + λI: O(k^2)</li>
<li>累加秩-1更新: O(n_u k^2)</li>
<li>Cholesky分解: O(k^3)</li>
<li>回代求解: O(k^2)</li>
</ul>
<p>总复杂度: O(n_u k^2 + k^3)
   ```</p>
<ol start="3">
<li>
<p><strong>内存访问模式优化</strong>：
   - <strong>缓存友好的矩阵存储</strong>：物品因子按列主序存储
   - <strong>分块计算</strong>：将 $\mathbf{Q}$ 分块以适应L3缓存
   - <strong>预取策略</strong>：利用用户访问模式预取下一批物品因子</p>
</li>
<li>
<p><strong>数值精度考虑</strong>：
   - 使用Cholesky分解代替直接求逆
   - 条件数监控：$\kappa(\mathbf{A}_u) &lt; 10^{10}$
   - 必要时增加正则化：$\lambda' = \lambda + \epsilon \cdot \text{trace}(\mathbf{A}_u)/k$</p>
</li>
</ol>
<h3 id="1422-als">14.2.2 分布式ALS的通信模式</h3>
<p>大规模部署需要精心设计的分布式策略：</p>
<ol>
<li><strong>数据并行模式</strong>：
   - 用户分片：每个节点负责一部分用户
   - 物品因子广播：$O(nk)$ 通信量
   - 适合用户数 $\gg$ 物品数的场景</li>
</ol>
<p><strong>详细实现</strong>：
   ```
   节点 p 负责用户集 U_p：</p>
<ol>
<li>广播接收全局 Q 矩阵</li>
<li>并行更新 P[U_p] </li>
<li>计算局部物品梯度 ΔQ_p</li>
<li>All-reduce 聚合 ΔQ = Σ_p ΔQ_p</li>
<li>本地更新 Q 矩阵
   ```</li>
</ol>
<p><strong>通信优化</strong>：</p>
<ul>
<li>使用环形all-reduce减少带宽需求</li>
<li>梯度压缩：只传输top-k梯度分量</li>
<li>异步通信与计算重叠</li>
</ul>
<ol start="2">
<li><strong>模型并行模式</strong>：
   - 因子矩阵分块：$\mathbf{P} = [\mathbf{P}_1, \mathbf{P}_2, ..., \mathbf{P}_p]$
   - 通信量：$O(mk/p)$ per iteration
   - 适合超大规模因子维度</li>
</ol>
<p><strong>2D分块策略</strong>：
$$\begin{bmatrix}
   \mathbf{P}_{11} &amp; \mathbf{P}_{12} &amp; \cdots \
   \mathbf{P}_{21} &amp; \mathbf{P}_{22} &amp; \cdots \
   \vdots &amp; \vdots &amp; \ddots
   \end{bmatrix}$$
每个节点 $(i,j)$ 负责 $\mathbf{P}_{ij}$ 和 $\mathbf{Q}_{ij}$</p>
<ol start="3">
<li>
<p><strong>混合并行策略</strong>：
   ```
   将用户分成 G 组，每组内执行：</p>
</li>
<li>
<p>本地更新用户因子</p>
</li>
<li>收集局部物品梯度</li>
<li>All-reduce 聚合梯度</li>
<li>更新物品因子
   ```</li>
</ol>
<p><strong>参数服务器架构</strong>：</p>
<ul>
<li>服务器节点：存储和更新物品因子</li>
<li>工作节点：计算用户更新和梯度</li>
<li>通信模式：Pull-Compute-Push</li>
</ul>
<p><strong>通信量分析</strong>：</p>
<ul>
<li>Pull阶段：每个worker拉取 $O(n_u k)$ 数据</li>
<li>Push阶段：每个worker推送 $O(n_u k)$ 梯度</li>
<li>总带宽：$O(Nnk/p)$，其中 $N$ 是总交互数</li>
</ul>
<ol start="4">
<li><strong>容错机制</strong>：
   - <strong>检查点</strong>：周期性保存因子矩阵快照
   - <strong>复制</strong>：关键参数多副本存储
   - <strong>异步备份</strong>：使用陈旧梯度继续训练</li>
</ol>
<p><strong>一致性保证</strong>：</p>
<ul>
<li>最终一致性：允许短期不一致</li>
<li>有界陈旧性：$\tau$-iteration staleness</li>
<li>收敛性证明：在有界延迟下仍收敛</li>
</ul>
<h3 id="1423">14.2.3 数值稳定性与收敛加速技巧</h3>
<p><strong>数值稳定性保障</strong>：</p>
<ol>
<li>
<p><strong>条件数控制</strong>：
$$\kappa(\mathbf{A}) = \frac{\lambda_{\max}(\mathbf{A})}{\lambda_{\min}(\mathbf{A})} &lt; \tau$$
通过自适应正则化保证：$\lambda = \max(\lambda_0, \epsilon \cdot |\mathbf{Q}^T\mathbf{C}^u\mathbf{Q}|_F)$</p>
</li>
<li>
<p><strong>Cholesky分解的增量更新</strong>：
   对于稀疏更新，使用 Sherman-Morrison 公式：
$$(\mathbf{A} + \mathbf{u}\mathbf{v}^T)^{-1} = \mathbf{A}^{-1} - \frac{\mathbf{A}^{-1}\mathbf{u}\mathbf{v}^T\mathbf{A}^{-1}}{1 + \mathbf{v}^T\mathbf{A}^{-1}\mathbf{u}}$$
<strong>收敛加速技术</strong>：</p>
</li>
<li>
<p><strong>动量方法</strong>：
$$\mathbf{p}_u^{(t+1)} = \mathbf{p}_u^{(t)} + \alpha \Delta\mathbf{p}_u^{(t)} + \beta(\mathbf{p}_u^{(t)} - \mathbf{p}_u^{(t-1)})$$</p>
</li>
<li>
<p><strong>自适应学习率</strong>：
   基于局部Lipschitz常数估计：
$$\alpha_u = \min\left(1, \frac{c}{|\nabla_{\mathbf{p}_u} \mathcal{L}|}\right)$$</p>
</li>
<li>
<p><strong>异步更新协议</strong>：
   - Hogwild!风格的无锁更新
   - 延迟补偿：$\mathbf{p}_u^{(t)} = \mathbf{p}_u^{(t-\tau)} + \sum_{s=t-\tau}^{t-1} \Delta\mathbf{p}_u^{(s)}$</p>
</li>
</ol>
<h3 id="1424">14.2.4 硬件感知优化</h3>
<p>现代硬件架构需要算法层面的适配：</p>
<ol>
<li>
<p><strong>缓存优化</strong>：
   - 分块矩阵乘法：块大小 $b = \sqrt{\text{L3 cache} / (3 \times \text{sizeof}(float))}$
   - 列主序存储用于物品因子</p>
</li>
<li>
<p><strong>SIMD向量化</strong>：
   - 内积计算使用 AVX-512：一次处理16个float
   - 对齐内存分配：<code>posix_memalign</code> 确保64字节对齐</p>
</li>
<li>
<p><strong>GPU加速考虑</strong>：
   - Warp级别的负载均衡
   - 使用 cuBLAS 的 <code>cublasXgemmBatched</code> 批量小矩阵运算</p>
</li>
</ol>
<h2 id="143">14.3 负采样的数学原理与偏差校正</h2>
<h3 id="1431">14.3.1 采样分布的理论选择</h3>
<p>负采样是隐式反馈系统的核心技术。给定正样本集 $\mathcal{D}^+$，我们需要从未观察到的 $(u,i)$ 对中采样负例。</p>
<p><strong>流行的采样分布</strong>：</p>
<ol>
<li>
<p><strong>均匀采样</strong>：
$$P_{\text{unif}}(i|u) = \frac{1}{|\mathcal{I} \setminus \mathcal{I}_u|}$$
简单但可能低估流行物品的负面信号。</p>
</li>
<li>
<p><strong>流行度比例采样</strong>：
$$P_{\text{pop}}(i|u) = \frac{f_i^\alpha}{\sum_{j \notin \mathcal{I}_u} f_j^\alpha}$$
其中 $f_i$ 是物品频率，$\alpha \in [0,1]$ 控制偏斜程度。</p>
</li>
<li>
<p><strong>自适应采样</strong>：
   基于当前模型预测：
$$P_{\text{adapt}}(i|u) \propto \sigma(\mathbf{p}_u^T\mathbf{q}_i)$$
类似于重要性采样，聚焦于"困难"负例。</p>
</li>
</ol>
<h3 id="1432">14.3.2 重要性采样与无偏估计</h3>
<p>使用非均匀采样时，需要校正引入的偏差：</p>
<p><strong>基础重要性采样</strong>：
$$\mathbb{E}_{i \sim P}[\frac{Q(i)}{P(i)} \cdot \ell(u,i)] = \mathbb{E}_{i \sim Q}[\ell(u,i)]$$
<strong>在负采样中的应用</strong>：
$$\mathcal{L}_{\text{unbiased}} = \sum_{(u,i) \in \mathcal{D}^+} \ell^+(u,i) + \sum_{j=1}^{K} \frac{1}{P(i_j^-|u)} \ell^-(u,i_j^-)$$
其中 $i_j^- \sim P(\cdot|u)$ 是采样的负例。</p>
<p><strong>方差减少技术</strong>：</p>
<ol>
<li>
<p><strong>控制变量法</strong>：
$$\tilde{\ell}(u,i) = \ell(u,i) - c(\ell(u,i) - \mu)$$
其中 $\mu = \mathbb{E}[\ell]$ 可以在线估计。</p>
</li>
<li>
<p><strong>分层采样</strong>：
   将物品按流行度分桶，每桶独立采样：
$$\mathcal{I} = \bigcup_{b=1}^{B} \mathcal{I}_b, \quad K_b = K \cdot \frac{|\mathcal{I}_b|}{|\mathcal{I}|}$$</p>
</li>
</ol>
<h3 id="1433">14.3.3 自适应采样策略</h3>
<p><strong>动态困难度感知采样</strong>：</p>
<ol>
<li>
<p><strong>基于梯度的重要性</strong>：
$$P(i|u) \propto |\nabla_{\mathbf{q}_i} \ell(u,i)|^2$$</p>
</li>
<li>
<p><strong>不确定性采样</strong>：
   使用参数的后验分布：
$$P(i|u) \propto \text{Var}[\mathbf{p}_u^T\mathbf{q}_i]$$
<strong>多目标采样</strong>：
同时优化多个目标（如覆盖度、多样性）：
$$P(i|u) = \sum_{k=1}^{K} w_k P_k(i|u)$$
其中权重 $w_k$ 可以动态调整。</p>
</li>
</ol>
<h3 id="1434">14.3.4 理论分析：收敛性与样本复杂度</h3>
<p><strong>收敛速率分析</strong>：
在适当的假设下，使用 $K$ 个负样本的SGD收敛速率为：
$$\mathbb{E}[|\mathbf{w}^{(t)} - \mathbf{w}^*|^2] \leq \frac{C}{t} + \frac{D}{K}$$
其中第二项反映了负采样引入的偏差。</p>
<p><strong>样本复杂度界</strong>：
达到 $\epsilon$-最优解所需的负样本数：
$$K = O\left(\frac{n \log n}{\epsilon^2}\right)$$
这解释了为什么实践中 $K=5-10$ 通常足够。</p>
<h2 id="144">14.4 置信度加权的理论基础</h2>
<h3 id="1441">14.4.1 贝叶斯视角下的置信度建模</h3>
<p>从贝叶斯角度，置信度反映了我们对观察到的隐式信号的不确定性。</p>
<p><strong>生成模型</strong>：</p>
<ol>
<li>真实偏好：$r_{ui}^* \sim \mathcal{N}(\mathbf{p}_u^T\mathbf{q}_i, \sigma^2)$</li>
<li>观察过程：$r_{ui} = r_{ui}^* + \epsilon_{ui}$</li>
<li>置信度：$c_{ui} = \frac{1}{\text{Var}[\epsilon_{ui}]}$</li>
</ol>
<p><strong>后验推断</strong>：
$$p(r_{ui}^*|r_{ui}) \propto \exp\left(-\frac{c_{ui}}{2}(r_{ui}^* - r_{ui})^2 - \frac{1}{2\sigma^2}(r_{ui}^* - \mathbf{p}_u^T\mathbf{q}_i)^2\right)$$
这导出了加权最小二乘的目标函数。</p>
<h3 id="1442">14.4.2 时间衰减与频率加权</h3>
<p><strong>时间动态建模</strong>：</p>
<ol>
<li>
<p><strong>指数衰减模型</strong>：
$$c_{ui}(t) = c_{ui}^{(0)} \exp(-\lambda_t(t - t_{ui}))$$</p>
</li>
<li>
<p><strong>幂律衰减</strong>：
$$c_{ui}(t) = c_{ui}^{(0)} (1 + t - t_{ui})^{-\alpha}$$
<strong>频率置信度</strong>：
基于观察次数的置信度估计：
$$c_{ui} = \frac{n_{ui}}{n_{ui} + \beta}$$
这是贝塔-二项式模型的后验均值。</p>
</li>
</ol>
<p><strong>联合建模</strong>：
$$c_{ui}(t, n) = f_{\text{time}}(t) \cdot f_{\text{freq}}(n) \cdot f_{\text{context}}(\mathbf{x})$$</p>
<h3 id="1443">14.4.3 在线更新的一致性保证</h3>
<p><strong>增量置信度更新</strong>：
新观察到达时：
$$c_{ui}^{(t+1)} = \frac{c_{ui}^{(t)} \cdot n_{ui}^{(t)} + \Delta c_{ui}}{n_{ui}^{(t)} + 1}$$
<strong>一致性条件</strong>：</p>
<ol>
<li><strong>单调性</strong>：$c_{ui}^{(t+1)} \geq c_{ui}^{(t)}$ 当有新正交互</li>
<li><strong>有界性</strong>：$c_{ui}^{(t)} \leq c_{\max}$ 防止过拟合</li>
<li><strong>收敛性</strong>：$\lim_{t \to \infty} c_{ui}^{(t)} = c_{ui}^*$ 存在</li>
</ol>
<p><strong>理论保证</strong>：
在适当的正则化下，在线更新算法满足：
$$\text{Regret}(T) = O(\sqrt{T \log n})$$</p>
<h3 id="1444">14.4.4 多源置信度融合</h3>
<p>现代系统需要整合多种信号：</p>
<ol>
<li>
<p><strong>层次贝叶斯模型</strong>：
$$c_{ui} \sim \text{Gamma}(\alpha_s, \beta_s), \quad s \in {\text{click}, \text{purchase}, ...}$$</p>
</li>
<li>
<p><strong>注意力机制融合</strong>：
$$c_{ui} = \sum_{s} a_s(\mathbf{u}, \mathbf{i}) \cdot c_{ui}^{(s)}$$
其中 $a_s$ 是学习的注意力权重。</p>
</li>
<li>
<p><strong>元学习置信度</strong>：
   使用MAML框架学习置信度函数：
$$c_{ui} = f_\phi(\mathbf{x}_{ui}), \quad \phi^* = \arg\min_\phi \mathbb{E}_{\mathcal{T}}[\mathcal{L}_{\mathcal{T}}(f_\phi)]$$</p>
</li>
</ol>
<h2 id="_1">本章小结</h2>
<p>本章深入探讨了大规模协同过滤中的核心矩阵技术。主要贡献包括：</p>
<ol>
<li>
<p><strong>隐式反馈的数学建模</strong>：
   - 置信度加权框架：$\min \sum_{(u,i)} c_{ui}(p_{ui} - \mathbf{p}_u^T\mathbf{q}_i)^2$
   - 从显式评分到隐式反馈的范式转变
   - 多源信号的统一处理框架</p>
</li>
<li>
<p><strong>ALS-WR的工程化实现</strong>：
   - 计算复杂度从 $O(mnk)$ 降至 $O((m+n)n_z k^2)$
   - 分布式并行的三种模式及其权衡
   - 数值稳定性保障与收敛加速</p>
</li>
<li>
<p><strong>负采样的理论基础</strong>：
   - 重要性采样实现无偏估计
   - 样本复杂度界：$K = O(\frac{n \log n}{\epsilon^2})$
   - 自适应采样策略的设计原则</p>
</li>
<li>
<p><strong>置信度的贝叶斯解释</strong>：
   - 不确定性量化的原则性方法
   - 时间动态与多源融合
   - 在线学习的一致性保证</p>
</li>
</ol>
<p><strong>关键洞察</strong>：</p>
<ul>
<li>隐式反馈的核心挑战是<strong>缺失并非随机</strong>（MNAR）</li>
<li>置信度加权提供了处理不确定性的统一框架</li>
<li>负采样效率决定了算法的可扩展性</li>
<li>硬件感知的优化对性能至关重要</li>
</ul>
<p><strong>未来研究方向</strong>：</p>
<ol>
<li>因果推断方法处理选择偏差</li>
<li>神经网络与矩阵分解的深度融合</li>
<li>联邦学习场景下的隐私保护矩阵分解</li>
<li>量子算法加速超大规模矩阵运算</li>
</ol>
<h2 id="_2">练习题</h2>
<h3 id="141_1">练习 14.1：置信度函数设计</h3>
<p>考虑一个视频推荐系统，用户行为包括：点击（click）、观看时长（watch_time）、点赞（like）、分享（share）。设计一个综合置信度函数 $c_{ui}$，满足以下要求：</p>
<ol>
<li>不同行为类型有不同权重</li>
<li>考虑时间衰减</li>
<li>防止极端值</li>
</ol>
<p><strong>提示</strong>：考虑使用对数变换处理长尾分布的观看时长。</p>
<details>
<summary>答案</summary>
<p>一个可能的设计：
$$c_{ui} = 1 + \alpha_1 \cdot \mathbb{1}[\text{click}] + \alpha_2 \cdot \log(1 + \text{watch_time}) + \alpha_3 \cdot \mathbb{1}[\text{like}] + \alpha_4 \cdot \mathbb{1}[\text{share}]$$
加入时间衰减：
$$c_{ui}(t) = c_{ui} \cdot \exp(-\lambda(t - t_{ui}))$$
防止极端值：
$$\tilde{c}_{ui} = \min(c_{ui}, c_{\max}) \cdot \frac{c_{ui}}{c_{ui} + \beta}$$
其中参数可以通过交叉验证确定，典型值：$\alpha_1 = 1, \alpha_2 = 0.5, \alpha_3 = 3, \alpha_4 = 5, \lambda = 0.01, \beta = 10, c_{\max} = 100$。</p>
</details>
<h3 id="142als">练习 14.2：ALS更新的向量化实现</h3>
<p>给定用户 $u$ 的交互物品集合 $\mathcal{I}_u = {i_1, i_2, ..., i_{n_u}}$ 和对应置信度 ${c_{ui_1}, c_{ui_2}, ..., c_{ui_{n_u}}}$，推导向量化的用户因子更新公式，避免显式构造对角矩阵 $\mathbf{C}^u$。</p>
<p><strong>提示</strong>：利用 $\mathbf{Q}^T\mathbf{C}^u\mathbf{Q} = \sum_{i \in \mathcal{I}_u} c_{ui}\mathbf{q}_i\mathbf{q}_i^T + \mathbf{Q}^T\mathbf{Q}$。</p>
<details>
<summary>答案</summary>
<p>向量化更新公式：
$$\mathbf{A}_u = \mathbf{Q}^T\mathbf{Q} + \sum_{i \in \mathcal{I}_u} (c_{ui} - 1)\mathbf{q}_i\mathbf{q}_i^T + \lambda\mathbf{I}$$</p>
<p>$$\mathbf{b}_u = \sum_{i \in \mathcal{I}_u} c_{ui} p_{ui} \mathbf{q}_i$$</p>
<p>$$\mathbf{p}_u = \mathbf{A}_u^{-1}\mathbf{b}_u$$
计算技巧：</p>
<ol>
<li>预计算 $\mathbf{Q}^T\mathbf{Q}$ 一次，所有用户共享</li>
<li>使用 BLAS 的 <code>syr</code> 操作高效计算秩-1更新</li>
<li>对于稀疏 $\mathcal{I}_u$，复杂度为 $O(|\mathcal{I}_u|k^2 + k^3)$</li>
</ol>
</details>
<h3 id="143_1">练习 14.3：负采样的方差分析</h3>
<p>证明：使用流行度比例采样 $P(i) \propto f_i^{0.75}$ 相比均匀采样，在估计全局损失时具有更低的方差。假设损失函数为 $\ell(u,i) = (\mathbf{p}_u^T\mathbf{q}_i)^2$。</p>
<p><strong>提示</strong>：计算两种采样策略下估计量的方差，并比较。</p>
<details>
<summary>答案</summary>
<p>设真实损失为 $L = \sum_{i \notin \mathcal{I}_u} \ell(u,i)$。</p>
<p>均匀采样估计量：
$$\hat{L}_{\text{unif}} = \frac{|\mathcal{I} \setminus \mathcal{I}_u|}{K} \sum_{j=1}^K \ell(u,i_j)$$
其方差：
$$\text{Var}[\hat{L}_{\text{unif}}] = \frac{|\mathcal{I} \setminus \mathcal{I}_u|^2}{K} \text{Var}_{i \sim \text{Unif}}[\ell(u,i)]$$
流行度采样估计量：
$$\hat{L}_{\text{pop}} = \sum_{j=1}^K \frac{\ell(u,i_j)}{P(i_j)}$$
其方差：
$$\text{Var}[\hat{L}_{\text{pop}}] = \frac{1}{K} \sum_{i \notin \mathcal{I}_u} \frac{\ell(u,i)^2}{P(i)} - \frac{L^2}{K}$$
当 $\ell(u,i)$ 与 $f_i$ 正相关时（流行物品得分更高），选择 $P(i) \propto f_i^{0.75}$ 使得 $\ell(u,i)/P(i)$ 更均匀，从而降低方差。</p>
</details>
<h3 id="144als">练习 14.4：分布式ALS的通信优化</h3>
<p>在分布式ALS中，假设有 $p$ 个计算节点，$m$ 个用户，$n$ 个物品，因子维度 $k$。分析以下三种数据分片策略的通信复杂度：</p>
<ol>
<li>随机分片</li>
<li>基于图分割的分片</li>
<li>块循环分片</li>
</ol>
<p><strong>提示</strong>：考虑每轮迭代需要传输的因子矩阵大小。</p>
<details>
<summary>答案</summary>
<ol>
<li>
<p><strong>随机分片</strong>：
   - 每个节点需要几乎所有物品因子
   - 通信量：$O(pnk)$ per iteration</p>
</li>
<li>
<p><strong>基于图分割</strong>：
   - 最小化跨分区边
   - 设边割比例为 $\rho$
   - 通信量：$O(\rho nk)$，其中 $\rho &lt; 1$</p>
</li>
<li>
<p><strong>块循环分片</strong>：
   - 用户和物品都分块
   - 每个节点负责 $\frac{m}{p} \times \frac{n}{p}$ 的块
   - 通信量：$O(\frac{(m+n)k}{\sqrt{p}})$</p>
</li>
</ol>
<p>结论：对于大规模系统，块循环分片在 $p$ 较大时最优。</p>
</details>
<h3 id="145">练习 14.5：增量更新的误差累积（挑战题）</h3>
<p>在流式场景中，使用增量Sherman-Morrison更新代替完全重算。分析经过 $T$ 次更新后的数值误差累积，并提出误差控制策略。</p>
<p><strong>提示</strong>：考虑浮点运算的舍入误差和条件数的影响。</p>
<details>
<summary>答案</summary>
<p>Sherman-Morrison更新：
$$\mathbf{A}^{-1}_{t+1} = \mathbf{A}^{-1}_t - \frac{\mathbf{A}^{-1}_t \mathbf{u}\mathbf{v}^T \mathbf{A}^{-1}_t}{1 + \mathbf{v}^T \mathbf{A}^{-1}_t \mathbf{u}}$$
误差分析：</p>
<ul>
<li>每步相对误差：$\epsilon_{\text{rel}} \approx \kappa(\mathbf{A}) \cdot \epsilon_{\text{machine}}$</li>
<li>$T$ 步后：$\epsilon_T \approx T \cdot \kappa(\mathbf{A}) \cdot \epsilon_{\text{machine}}$</li>
</ul>
<p>误差控制策略：</p>
<ol>
<li><strong>周期性重算</strong>：每 $T_0 = \frac{1}{\kappa(\mathbf{A}) \cdot \epsilon_{\text{machine}}}$ 步完全重算</li>
<li><strong>条件数监控</strong>：当 $\kappa(\mathbf{A}_t) &gt; \tau$ 时触发重算</li>
<li><strong>残差检验</strong>：检查 $|\mathbf{A}_t \mathbf{A}_t^{-1} - \mathbf{I}|_F &lt; \delta$</li>
</ol>
</details>
<h3 id="146">练习 14.6：多目标优化的帕累托前沿（挑战题）</h3>
<p>推荐系统需要同时优化准确性（RMSE）、覆盖度（Coverage）和多样性（Diversity）。设计一个多目标矩阵分解框架，并分析帕累托最优解的性质。</p>
<p><strong>提示</strong>：考虑加权和方法和约束优化方法。</p>
<details>
<summary>答案</summary>
<p>多目标优化框架：
$$\min_{\mathbf{P},\mathbf{Q}} \alpha_1 \cdot \text{RMSE} + \alpha_2 \cdot (1-\text{Coverage}) + \alpha_3 \cdot (1-\text{Diversity})$$
其中：</p>
<ul>
<li>$\text{RMSE} = \sqrt{\frac{1}{|\mathcal{D}|}\sum_{(u,i) \in \mathcal{D}} (r_{ui} - \mathbf{p}_u^T\mathbf{q}_i)^2}$</li>
<li>$\text{Coverage} = \frac{|{i: \exists u, \mathbf{p}_u^T\mathbf{q}_i &gt; \theta}|}{n}$</li>
<li>$\text{Diversity} = 1 - \frac{1}{|\mathcal{U}|}\sum_u \frac{\sum_{i,j \in \text{Top-K}(u)} \text{sim}(i,j)}{K(K-1)}$</li>
</ul>
<p>帕累托前沿特性：</p>
<ol>
<li>凸性：在温和假设下，帕累托前沿局部凸</li>
<li>权衡关系：$\frac{\partial \text{Coverage}}{\partial \text{RMSE}} &lt; 0$</li>
<li>锚点解：纯准确性优化 vs 纯多样性优化</li>
</ol>
<p>实践建议：使用进化算法（如NSGA-II）探索帕累托前沿。</p>
</details>
<h3 id="147">练习 14.7：联邦学习中的隐私保护矩阵分解（开放题）</h3>
<p>设计一个满足差分隐私的分布式矩阵分解算法，其中用户数据不能离开本地设备。分析隐私-效用权衡。</p>
<p><strong>提示</strong>：考虑梯度扰动和安全聚合。</p>
<details>
<summary>答案</summary>
<p>算法框架：</p>
<ol>
<li>
<p><strong>本地更新</strong>：用户 $u$ 在设备上计算：
$$\mathbf{p}_u^{(t+1)} = \mathbf{p}_u^{(t)} - \eta \nabla_{\mathbf{p}_u} \mathcal{L}_u$$</p>
</li>
<li>
<p><strong>梯度扰动</strong>：添加高斯噪声实现 $(\epsilon, \delta)$-差分隐私：
$$\tilde{\nabla} = \nabla + \mathcal{N}(0, \sigma^2 \mathbf{I})$$
其中 $\sigma = \frac{2\Delta_f \sqrt{2\log(1.25/\delta)}}{\epsilon}$</p>
</li>
<li>
<p><strong>安全聚合</strong>：
   使用秘密分享或同态加密聚合物品梯度：
$$\nabla_{\mathbf{q}_i} = \sum_{u \in \mathcal{U}_i} \tilde{\nabla}_{u,i}$$
隐私-效用分析：</p>
</li>
</ol>
<ul>
<li>隐私损失：$\epsilon_{\text{total}} = \sqrt{2T\log(1/\delta)} \cdot \epsilon$</li>
<li>效用损失：$\text{RMSE}_{\text{private}} - \text{RMSE}_{\text{non-private}} \approx O(\frac{k\sqrt{T}}{\epsilon n})$</li>
</ul>
<p>研究方向：</p>
<ol>
<li>自适应隐私预算分配</li>
<li>个性化隐私级别</li>
<li>与同态加密结合减少噪声</li>
</ol>
</details>
<h3 id="148">练习 14.8：因果推断视角的去偏（研究题）</h3>
<p>将推荐系统的选择偏差建模为因果图，使用do-calculus推导无偏的损失函数。考虑观察概率 $P(O=1|U,I,R)$ 依赖于真实评分 $R$ 的情况。</p>
<p><strong>提示</strong>：构建因果图 $U \rightarrow R \leftarrow I, R \rightarrow O$。</p>
<details>
<summary>答案</summary>
<p>因果模型：</p>
<ul>
<li>$U$：用户特征</li>
<li>$I$：物品特征</li>
<li>$R$：真实评分</li>
<li>$O$：是否观察到</li>
</ul>
<p>目标：估计 $\mathbb{E}[R|U,I]$</p>
<p>观察到的数据分布：
$$P(R|U,I,O=1) = \frac{P(O=1|U,I,R)P(R|U,I)}{P(O=1|U,I)}$$
使用逆倾向分数加权：
$$\mathbb{E}[R|U,I] = \frac{\mathbb{E}[R \cdot \mathbb{1}[O=1] / P(O=1|U,I,R)|U,I]}{\mathbb{E}[\mathbb{1}[O=1] / P(O=1|U,I,R)|U,I]}$$</p>
<p>实践中的挑战：</p>
<ol>
<li>估计 $P(O=1|U,I,R)$ 需要反事实推理</li>
<li>倾向分数的极值导致高方差</li>
<li>模型误设的敏感性</li>
</ol>
<p>研究方向：</p>
<ul>
<li>双鲁棒估计</li>
<li>敏感性分析</li>
<li>与强化学习的结合</li>
</ul>
</details>
<h2 id="gotchas">常见陷阱与错误 (Gotchas)</h2>
<h3 id="1">1. 数值稳定性陷阱</h3>
<p><strong>问题</strong>：直接计算 $\mathbf{Q}^T\mathbf{C}^u\mathbf{Q}$ 导致数值不稳定</p>
<div class="codehilite"><pre><span></span><code><span class="gh">#</span> 错误做法
A = Q.T @ diag(C_u) @ Q  # 当C_u包含极大值时条件数爆炸
</code></pre></div>

<p><strong>正确做法</strong>：</p>
<ul>
<li>使用增量更新：$\mathbf{A} = \mathbf{Q}^T\mathbf{Q} + \sum_i (c_{ui}-1)\mathbf{q}_i\mathbf{q}_i^T$</li>
<li>添加自适应正则化：$\lambda = \max(\lambda_0, \epsilon \cdot \text{trace}(\mathbf{A}))$</li>
</ul>
<h3 id="2">2. 负采样偏差</h3>
<p><strong>问题</strong>：均匀负采样导致流行物品的负信号不足</p>
<ul>
<li>热门物品被大量用户忽略，但采样概率与冷门物品相同</li>
<li>导致模型过度推荐流行物品</li>
</ul>
<p><strong>解决方案</strong>：</p>
<ul>
<li>使用流行度加权采样：$P(i) \propto f_i^{0.75}$</li>
<li>实施重要性权重校正</li>
</ul>
<h3 id="3">3. 冷启动过拟合</h3>
<p><strong>问题</strong>：新用户/物品的因子向量快速过拟合到少量交互</p>
<ul>
<li>置信度函数对初始交互赋予过高权重</li>
<li>正则化不足导致因子向量norm过大</li>
</ul>
<p><strong>缓解策略</strong>：</p>
<ul>
<li>动态正则化：$\lambda_u = \lambda_0 \cdot \max(1, n_0/n_u)$</li>
<li>使用先验信息初始化因子</li>
</ul>
<h3 id="4">4. 分布式训练的数据倾斜</h3>
<p><strong>问题</strong>：用户活跃度的幂律分布导致计算负载不均</p>
<ul>
<li>某些节点处理超级活跃用户，成为瓶颈</li>
<li>简单的哈希分片加剧问题</li>
</ul>
<p><strong>解决方案</strong>：</p>
<ul>
<li>基于计算量的动态负载均衡</li>
<li>将超级用户的计算分散到多个节点</li>
</ul>
<h3 id="5">5. 时间动态的过度拟合</h3>
<p><strong>问题</strong>：过于激进的时间衰减导致历史信息丢失</p>
<ul>
<li>指数衰减参数设置过大</li>
<li>短期行为主导，长期偏好被忽略</li>
</ul>
<p><strong>平衡方法</strong>：</p>
<ul>
<li>使用多尺度时间建模</li>
<li>保留用户的"核心偏好"不衰减</li>
</ul>
<h3 id="6">6. 隐式到显式的误导转换</h3>
<p><strong>问题</strong>：将隐式反馈二值化时丢失重要信息</p>
<div class="codehilite"><pre><span></span><code><span class="gh">#</span> 危险的简化
p_ui = 1 if r_ui &gt; 0 else 0  # 忽略了交互强度
</code></pre></div>

<p><strong>更好的做法</strong>：</p>
<ul>
<li>保留连续值：$p_{ui} = \log(1 + r_{ui})$</li>
<li>使用置信度区分不同强度的信号</li>
</ul>
<h3 id="7">7. 并行更新的竞态条件</h3>
<p><strong>问题</strong>：Hogwild!式并行更新在高竞争区域失效</p>
<ul>
<li>热门物品的因子被频繁更新</li>
<li>梯度延迟导致收敛不稳定</li>
</ul>
<p><strong>缓解措施</strong>：</p>
<ul>
<li>使用延迟补偿SGD</li>
<li>对高竞争参数使用锁或原子操作</li>
</ul>
<h3 id="8">8. 评估指标的误导性</h3>
<p><strong>问题</strong>：离线指标（如RMSE）与在线业务指标脱节</p>
<ul>
<li>RMSE优化可能降低推荐多样性</li>
<li>忽略了位置偏差和展示偏差</li>
</ul>
<p><strong>全面评估</strong>：</p>
<ul>
<li>同时监控准确性、覆盖度、多样性</li>
<li>进行在线A/B测试验证</li>
</ul>
<h2 id="_3">最佳实践检查清单</h2>
<h3 id="_4">数据预处理</h3>
<ul>
<li>[ ] 识别并处理异常用户行为（如机器人）</li>
<li>[ ] 对长尾分布的交互强度进行对数变换</li>
<li>[ ] 实施合理的时间窗口截断</li>
<li>[ ] 验证用户-物品交互矩阵的稀疏度</li>
</ul>
<h3 id="_5">算法设计</h3>
<ul>
<li>[ ] 置信度函数考虑多种信号类型</li>
<li>[ ] 正则化参数根据用户/物品活跃度自适应</li>
<li>[ ] 负采样策略平衡效率与无偏性</li>
<li>[ ] 实现增量更新以支持在线学习</li>
</ul>
<h3 id="_6">数值计算</h3>
<ul>
<li>[ ] 使用数值稳定的矩阵运算（避免显式求逆）</li>
<li>[ ] 监控条件数，必要时增加正则化</li>
<li>[ ] 利用稀疏性减少计算复杂度</li>
<li>[ ] 实施周期性的完全重算以控制误差累积</li>
</ul>
<h3 id="_7">分布式实现</h3>
<ul>
<li>[ ] 选择适合数据特征的分片策略</li>
<li>[ ] 实现高效的因子广播/聚合机制</li>
<li>[ ] 处理节点故障和网络延迟</li>
<li>[ ] 监控和均衡计算负载</li>
</ul>
<h3 id="_8">性能优化</h3>
<ul>
<li>[ ] 利用SIMD指令加速向量运算</li>
<li>[ ] 优化内存访问模式（缓存友好）</li>
<li>[ ] 使用异步I/O减少等待时间</li>
<li>[ ] Profile识别性能瓶颈</li>
</ul>
<h3 id="_9">模型评估</h3>
<ul>
<li>[ ] 设计考虑时间因素的训练/测试集划分</li>
<li>[ ] 评估多个维度：准确性、覆盖度、多样性、新颖性</li>
<li>[ ] 进行消融实验验证各组件贡献</li>
<li>[ ] 监控模型在不同用户群体上的公平性</li>
</ul>
<h3 id="_10">生产部署</h3>
<ul>
<li>[ ] 实现模型版本管理和回滚机制</li>
<li>[ ] 设置异常检测和报警</li>
<li>[ ] 支持热更新without服务中断</li>
<li>[ ] 记录详细日志用于问题诊断</li>
</ul>
<h3 id="_11">持续改进</h3>
<ul>
<li>[ ] 收集在线反馈用于模型迭代</li>
<li>[ ] 定期重新评估超参数</li>
<li>[ ] 探索新的特征和信号源</li>
<li>[ ] 跟踪学术界最新进展并评估适用性</li>
</ul>
            </article>
            
            <nav class="page-nav"><a href="./chapter13.html" class="nav-link prev">← 第13章：动态低秩近似</a><a href="./chapter15.html" class="nav-link next">第15章：实时推荐的增量矩阵方法 →</a></nav>
        </main>
    </div>
</body>
</html>