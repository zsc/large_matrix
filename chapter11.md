# 第11章：流形预条件技术

流形优化中的预条件技术是将欧氏空间中成熟的二阶方法推广到曲线空间的关键桥梁。本章深入探讨如何在保持几何结构的同时，利用曲率信息加速收敛。我们将看到，恰当的预条件不仅能显著提升算法效率，还能揭示问题的内在几何结构。

## 11.1 流形上的Natural Gradient

### 11.1.1 从信息几何到优化

在机器学习中，参数空间往往具有自然的Riemannian结构。最典型的例子是概率分布的参数空间，其上的Fisher信息矩阵定义了一个自然的Riemannian度量：

$$g_{ij}(\theta) = \mathbb{E}_{p(x|\theta)}\left[\frac{\partial \log p(x|\theta)}{\partial \theta_i} \frac{\partial \log p(x|\theta)}{\partial \theta_j}\right]$$

Natural Gradient方法的核心思想是在这个几何结构下进行最陡下降：

$$\theta_{k+1} = \theta_k - \alpha_k G^{-1}(\theta_k) \nabla f(\theta_k)$$

其中$G(\theta)$是度量张量的矩阵表示。

### 11.1.2 流形Natural Gradient的一般形式

对于一般的Riemannian流形$\mathcal{M}$，Natural Gradient更新可以写成：

$$x_{k+1} = \mathcal{R}_{x_k}(-\alpha_k \xi_k)$$

其中：
- $\xi_k = G_{x_k}^{-1}(\text{grad} f(x_k))$是预条件后的搜索方向
- $G_{x_k}$是点$x_k$处的Riemannian度量
- $\mathcal{R}_{x_k}$是回缩映射

关键观察：Natural Gradient在流形上的表现形式自然地结合了几何结构和函数的局部信息。

### 11.1.3 度量选择的艺术

不同的度量选择导致不同的算法行为：

1. **标准度量**：对于$\text{St}(p,n)$（Stiefel流形），标准度量是
   $$g_X(\xi, \eta) = \text{tr}(\xi^T(I - \frac{1}{2}XX^T)\eta)$$

2. **欧氏度量**：简单地继承环境空间的度量
   $$g_X(\xi, \eta) = \text{tr}(\xi^T\eta)$$

3. **问题相关度量**：基于目标函数的Hessian信息构造
   $$g_X(\xi, \eta) = \langle \xi, \mathcal{H}_X[\eta] \rangle$$

### 11.1.4 高效实现策略

计算$G^{-1}\text{grad} f$的主要挑战在于：
- 度量张量可能是稠密的
- 直接求逆计算代价高昂
- 数值稳定性要求

实践中常用的技巧包括：
1. **对角近似**：当度量接近对角时，使用对角预条件
2. **低秩修正**：利用Woodbury公式处理低秩扰动
3. **迭代求解**：使用共轭梯度法求解线性系统$G\xi = \text{grad} f$

### 11.1.5 收敛性分析要点

Natural Gradient在流形上的收敛性依赖于：
- 度量的Lipschitz连续性
- 目标函数的测地凸性
- 步长选择策略

关键定理：在适当条件下，Natural Gradient达到局部二次收敛率。

### 11.1.6 与经典方法的联系

有趣的是，许多经典算法可以视为特定流形上的Natural Gradient：
- **矩阵Scaling**：正定矩阵流形上的Natural Gradient
- **Riemannian共轭梯度**：使用特定度量的预条件共轭梯度
- **测地Newton法**：二阶Natural Gradient

## 11.2 Riemannian BFGS方法

### 11.2.1 动机与基本思想

BFGS方法在欧氏空间中的成功激发了其在流形上的推广。核心挑战在于如何在曲线空间中维护和更新Hessian近似。Riemannian BFGS (RBFGS)通过巧妙利用向量传输解决了这一问题。

基本更新公式遵循拟Newton条件：
$$\mathcal{H}_{k+1} s_k = y_k$$

其中：
- $s_k = \mathcal{T}_{x_k}^{x_{k+1}} \xi_k$是步长的向量传输
- $y_k = \text{grad} f(x_{k+1}) - \mathcal{T}_{x_k}^{x_{k+1}} \text{grad} f(x_k)$

### 11.2.2 向量传输的选择

向量传输$\mathcal{T}$的选择对算法性能至关重要：

1. **平行传输**：保持向量"方向"不变，理论性质最好
   - 优点：保度量、保正交性
   - 缺点：计算代价可能很高

2. **投影传输**：简单地投影到切空间
   $$\mathcal{T}_{x}^{y} \xi = \mathcal{P}_{T_y\mathcal{M}} \xi$$
   - 优点：计算简单
   - 缺点：可能不保度量

3. **向量场传输**：利用流形的向量场结构
   - 适用于具有Lie群作用的流形

### 11.2.3 RBFGS更新公式

给定当前Hessian近似$\mathcal{H}_k$，更新公式为：

$$\mathcal{H}_{k+1} = \mathcal{H}_k - \frac{\mathcal{H}_k s_k s_k^T \mathcal{H}_k}{s_k^T \mathcal{H}_k s_k} + \frac{y_k y_k^T}{y_k^T s_k}$$

注意：所有运算都在切空间$T_{x_{k+1}}\mathcal{M}$中进行。

### 11.2.4 有限内存变体 (L-RBFGS)

对于大规模问题，有限内存版本更实用：

1. 存储最近$m$对$(s_i, y_i)$
2. 使用两循环递归计算搜索方向
3. 初始Hessian近似的巧妙选择：
   $$\mathcal{H}_0 = \frac{y_{k-1}^T s_{k-1}}{y_{k-1}^T y_{k-1}} I$$

### 11.2.5 数值稳定性考虑

RBFGS实现中的关键数值问题：

1. **曲率条件**：确保$y_k^T s_k > 0$
   - 可能需要修正$y_k$或使用阻尼策略

2. **正定性维护**：
   - 使用修正BFGS公式
   - Powell-Wolfe线搜索条件

3. **向量传输的数值误差**：
   - 累积误差可能破坏收敛性
   - 定期重置或重正交化

### 11.2.6 收敛性理论

关键结果：
- **局部超线性收敛**：在适当条件下，RBFGS达到超线性收敛率
- **全局收敛**：配合适当的线搜索，保证全局收敛到驻点

收敛速度依赖于：
- 向量传输的等距性
- Hessian的Lipschitz连续性
- 初始点选择

### 11.2.7 实际应用案例

1. **低秩矩阵优化**：在Grassmann流形上的RBFGS
2. **张量分解**：在乘积流形上的应用
3. **深度学习**：正交约束下的网络训练

## 11.3 几何感知的Trust Region

### 11.3.1 流形Trust Region的基本框架

Trust Region方法在流形优化中特别有效，因为它自然地处理了曲率带来的非线性。基本思想是在每次迭代中求解子问题：

$$\min_{\xi \in T_x\mathcal{M}} m_k(\xi) \quad \text{s.t.} \quad \|\xi\|_x \leq \Delta_k$$

其中$m_k(\xi)$是目标函数的局部近似模型。

### 11.3.2 模型构造的艺术

不同的模型选择导致不同的算法特性：

1. **一阶模型**：
   $$m_k(\xi) = f(x_k) + \langle \text{grad} f(x_k), \xi \rangle_x$$

2. **二阶模型**：
   $$m_k(\xi) = f(x_k) + \langle \text{grad} f(x_k), \xi \rangle_x + \frac{1}{2}\langle \xi, \text{Hess} f(x_k)[\xi] \rangle_x$$

3. **拟Newton模型**：使用RBFGS近似替代真实Hessian

### 11.3.3 子问题求解策略

Trust Region子问题在流形上的求解面临独特挑战：

1. **Cauchy点计算**：
   - 沿负梯度方向的最优步长
   - 提供下界保证

2. **截断共轭梯度法** (tCG)：
   - 在切空间中迭代求解
   - 遇到负曲率时提前终止

3. **Steihaug-Toint算法的流形推广**：
   - 结合CG迭代与Trust Region约束
   - 自适应处理负曲率

### 11.3.4 回缩映射的选择与影响

回缩映射$\mathcal{R}_x$将切向量映射回流形，其选择影响：

1. **计算效率**：指数映射vs投影回缩
2. **近似质量**：二阶vs一阶回缩
3. **数值稳定性**：大步长时的行为

关键性质：
$$\mathcal{R}_x(t\xi) = \gamma(t)$$
其中$\gamma$是从$x$出发、初始速度为$\xi$的测地线。

### 11.3.5 自适应半径调整

Trust Region半径$\Delta_k$的调整策略：

1. **预测比率**：
   $$\rho_k = \frac{f(x_k) - f(\mathcal{R}_{x_k}(\xi_k))}{m_k(0) - m_k(\xi_k)}$$

2. **更新规则**：
   - 若$\rho_k < 0.25$：$\Delta_{k+1} = 0.25\Delta_k$
   - 若$\rho_k > 0.75$且$\|\xi_k\| = \Delta_k$：$\Delta_{k+1} = 2\Delta_k$
   - 否则：$\Delta_{k+1} = \Delta_k$

3. **几何考虑**：
   - 考虑流形的内蕴曲率
   - 在高曲率区域使用更保守的半径

### 11.3.6 收敛性分析

Trust Region方法在流形上的收敛性质：

1. **全局收敛**：从任意初始点收敛到一阶驻点
2. **局部收敛速度**：
   - 使用精确Hessian：二次收敛
   - 使用RBFGS近似：超线性收敛

关键假设：
- 目标函数在回缩邻域内Lipschitz连续
- 模型充分近似真实函数

### 11.3.7 与线搜索方法的比较

Trust Region vs 线搜索在流形优化中的权衡：

1. **Trust Region优势**：
   - 自然处理负曲率
   - 对病态问题更稳健
   - 理论保证更强

2. **线搜索优势**：
   - 实现相对简单
   - 每步计算代价较低
   - 对某些流形结构更自然

3. **混合策略**：
   - 在Trust Region框架中使用线搜索
   - 自适应切换策略

## 11.4 与欧氏空间方法的性能对比

### 11.4.1 理论复杂度分析

比较流形方法与投影方法的计算复杂度：

1. **每次迭代成本**：
   - 欧氏投影方法：$\mathcal{O}(n^2) + $ 投影成本
   - Riemannian方法：$\mathcal{O}(n^2) + $ 回缩成本
   
   关键观察：对许多流形，回缩和投影的成本相当。

2. **收敛速度**：
   - 欧氏方法：线性到超线性（取决于曲率）
   - Riemannian方法：保持原始收敛率

3. **内存需求**：
   - L-BFGS vs L-RBFGS：相同的$\mathcal{O}(mn)$
   - Trust Region：额外的子问题求解器内存

### 11.4.2 数值实验基准

典型测试问题的性能对比：

1. **低秩矩阵补全**（Grassmann流形）：
   - 问题规模：$1000 \times 1000$，秩$r=10$
   - Riemannian方法通常快2-5倍
   - 在高噪声情况下优势更明显

2. **特征值优化**（Stiefel流形）：
   - 寻找主特征空间
   - 几何方法避免了重复正交化
   - 数值稳定性显著提升

3. **张量分解**（乘积流形）：
   - Tucker分解、CP分解
   - 利用流形结构减少约束违反

### 11.4.3 算法选择指南

何时使用流形预条件方法：

1. **强烈推荐场景**：
   - 约束曲率大
   - 问题具有自然的几何结构
   - 需要高精度解
   - 欧氏方法收敛缓慢

2. **谨慎使用场景**：
   - 流形运算（如回缩）代价过高
   - 问题规模极大，内存受限
   - 只需要低精度解
   - 缺乏高效的流形运算实现

### 11.4.4 实现优化技巧

提升流形方法性能的关键技巧：

1. **缓存几何量**：
   - 度量张量的Cholesky分解
   - 常用的投影算子
   - Christoffel符号（如需要）

2. **自适应精度**：
   - 初期使用低精度回缩
   - 接近收敛时提高精度
   - 动态调整子问题求解精度

3. **并行化机会**：
   - 向量传输的批处理
   - 多个搜索方向的并行评估
   - Trust Region子问题的并行求解

### 11.4.5 鲁棒性比较

数值稳定性和鲁棒性分析：

1. **条件数敏感性**：
   - 欧氏方法：受环境空间条件数影响
   - 流形方法：仅受内蕴条件数影响

2. **初始化敏感性**：
   - 流形方法通常有更大的收敛域
   - 几何结构提供了自然的正则化

3. **参数调优**：
   - 流形方法的超参数通常更少
   - 默认参数的鲁棒性更好

### 11.4.6 前沿研究方向

1. **自适应流形选择**：
   - 动态调整工作流形
   - 多流形融合策略

2. **硬件加速**：
   - GPU上的流形运算
   - 专用硬件设计

3. **与深度学习的结合**：
   - 神经网络中的流形层
   - 几何深度学习的优化

4. **随机流形方法**：
   - 流形上的SGD变体
   - 方差缩减技术的推广
